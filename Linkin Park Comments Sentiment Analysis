{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":9977030,"sourceType":"datasetVersion","datasetId":6138800}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:08.021992Z","iopub.execute_input":"2024-11-22T01:18:08.022678Z","iopub.status.idle":"2024-11-22T01:18:08.033034Z","shell.execute_reply.started":"2024-11-22T01:18:08.022644Z","shell.execute_reply":"2024-11-22T01:18:08.031859Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Import Libraries","metadata":{}},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n#NLP Libraries\nfrom googleapiclient.discovery import build\nfrom bs4 import BeautifulSoup\nfrom transformers import pipeline \nimport torch\n \nfrom transformers import pipeline\nfrom datasets import Dataset\nfrom tqdm.notebook import tqdm_notebook ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:37.936324Z","iopub.execute_input":"2024-11-22T01:18:37.937041Z","iopub.status.idle":"2024-11-22T01:18:37.942024Z","shell.execute_reply.started":"2024-11-22T01:18:37.937004Z","shell.execute_reply":"2024-11-22T01:18:37.941092Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_videos = pd.read_csv('/kaggle/input/linkin-park-youtube-video-comments-for-nlp/linkin_park_youtube.csv',index_col=0)\ndf_comments = pd.read_csv('/kaggle/input/linkin-park-youtube-video-comments-for-nlp/linkin_park_youtube_comments.csv', index_col=0)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:40.590577Z","iopub.execute_input":"2024-11-22T01:18:40.590937Z","iopub.status.idle":"2024-11-22T01:18:42.511023Z","shell.execute_reply.started":"2024-11-22T01:18:40.590906Z","shell.execute_reply":"2024-11-22T01:18:42.510197Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_comments.dropna(subset='Comment', inplace=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:43.190382Z","iopub.execute_input":"2024-11-22T01:18:43.190723Z","iopub.status.idle":"2024-11-22T01:18:43.315226Z","shell.execute_reply.started":"2024-11-22T01:18:43.190696Z","shell.execute_reply":"2024-11-22T01:18:43.314410Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_videos","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:44.762248Z","iopub.execute_input":"2024-11-22T01:18:44.762636Z","iopub.status.idle":"2024-11-22T01:18:44.783622Z","shell.execute_reply.started":"2024-11-22T01:18:44.762603Z","shell.execute_reply":"2024-11-22T01:18:44.782756Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_comments.head(10)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:48.595576Z","iopub.execute_input":"2024-11-22T01:18:48.595975Z","iopub.status.idle":"2024-11-22T01:18:48.609123Z","shell.execute_reply.started":"2024-11-22T01:18:48.595939Z","shell.execute_reply":"2024-11-22T01:18:48.607972Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_comments.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:50.495798Z","iopub.execute_input":"2024-11-22T01:18:50.496185Z","iopub.status.idle":"2024-11-22T01:18:50.502391Z","shell.execute_reply.started":"2024-11-22T01:18:50.496153Z","shell.execute_reply":"2024-11-22T01:18:50.501300Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_comments.info()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:18:52.231411Z","iopub.execute_input":"2024-11-22T01:18:52.232246Z","iopub.status.idle":"2024-11-22T01:18:52.328726Z","shell.execute_reply.started":"2024-11-22T01:18:52.232171Z","shell.execute_reply":"2024-11-22T01:18:52.327575Z"}},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Sentiment Analysis using Hugging Face Transformers","metadata":{}},{"cell_type":"code","source":"# Load the sentiment analysis pipeline using a pre-trained RoBERTa model\nmodel_name = \"cardiffnlp/twitter-roberta-base-sentiment\" \nsentiment_pipeline = pipeline(\n    \"sentiment-analysis\",\n    model=model_name,\n    tokenizer=model_name,\n    truncation=True,\n    max_length=512,\n    device=0\n)\n# Function to process a batch of comments\ndef analyze_and_map_sentiment_batch(batch):\n    try:\n        # Ensure the batch has valid comments\n        comments = batch[\"Comment\"]\n        results = sentiment_pipeline(comments, truncation=True, max_length=512)\n        \n        # Map RoBERTa labels to human-readable sentiments\n        mapped_results = []\n        for result in results:\n            label = result[\"label\"]\n            if label == \"LABEL_2\":\n                mapped_results.append(\"positive\")\n            elif label == \"LABEL_1\":\n                mapped_results.append(\"neutral\")\n            elif label == \"LABEL_0\":\n                mapped_results.append(\"negative\")\n            else:\n                mapped_results.append(\"unknown\")\n        return {\"Sentiment\": mapped_results}\n    except Exception as e:\n        print(f\"Error processing batch: {e}\")\n        return {\"Sentiment\": [\"unknown\"] * len(batch[\"Comment\"])}\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:19:15.040169Z","iopub.execute_input":"2024-11-22T01:19:15.040553Z","iopub.status.idle":"2024-11-22T01:19:21.078489Z","shell.execute_reply.started":"2024-11-22T01:19:15.040522Z","shell.execute_reply":"2024-11-22T01:19:21.077649Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Drop rows where 'Comment' is NaN\ndf_comments = df_comments.dropna(subset=['Comment'])\n\n# Convert the comments DataFrame to a Hugging Face Dataset\ndataset = Dataset.from_pandas(df_comments)\n\n# Apply the sentiment analysis pipeline in batches\ntqdm_notebook.pandas(desc=\"Processing Sentiment in Batches\")\nresults = dataset.map(analyze_and_map_sentiment_batch, batched=True, batch_size=8)\n# Add the results back to the original DataFrame\ndf_comments[\"Sentiment\"] = results[\"Sentiment\"]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:27:11.545192Z","iopub.execute_input":"2024-11-22T01:27:11.546086Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df_comments.to_csv('/kaggle/working/youtube_comments_sentiments.csv')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-22T01:25:27.719062Z","iopub.status.idle":"2024-11-22T01:25:27.719445Z","shell.execute_reply.started":"2024-11-22T01:25:27.719256Z","shell.execute_reply":"2024-11-22T01:25:27.719275Z"}},"outputs":[],"execution_count":null}]}